{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"]=\"1\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from sentence_transformers import util, SentenceTransformer\n",
    "\n",
    "# -----\n",
    "\n",
    "device = \"mps:0\"\n",
    "data_df_save_path = \"localRAG.csv\"\n",
    "embeddings_df_save_path = \"localRAG_embs.csv\"\n",
    "modelpath = \"google/gemma-2-2b-it\" # \"ministral/Ministral-3b-instruct\"\n",
    "emb_model_name = \"mixedbread-ai/mxbai-embed-large-v1\" \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4881103fce16434687e8fc262a79363e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#quantization_config = BitsAndBytesConfig(load_in_8bit=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    modelpath,    \n",
    "    device_map=\"auto\",\n",
    "    # quantization_config=quantization_config,\n",
    "    # attn_implementation=\"flash_attention_2\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "embedding_model = SentenceTransformer(model_name_or_path=emb_model_name, \n",
    "                                      device=device)\n",
    "embedding_model.to(device)\n",
    "\n",
    "# Load (slow) Tokenizer, fast tokenizer sometimes ignores added tokens\n",
    "# Requires sentencepiece\n",
    "tokenizer = AutoTokenizer.from_pretrained(modelpath)   \n",
    "#tokenizer.add_special_tokens(dict(eos_token=\"</s>\"))\n",
    "\n",
    "#-----\n",
    "\n",
    "df = pd.read_csv(data_df_save_path)\n",
    "embeddings_df = pd.read_csv(embeddings_df_save_path)\n",
    "embeddings = torch.from_numpy(embeddings_df.values).to(device=device, dtype=torch.float32)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_topk_texts(query: str,\n",
    "                        k_resources_to_return: int=5,\n",
    "                        ):\n",
    "    #query prompting specific to mixedbread model\n",
    "    query = f'Represent this sentence for searching relevant passages: {query}'\n",
    "    query_embedding = embedding_model.encode(query, convert_to_tensor=True)\n",
    "    dot_scores = util.dot_score(a=query_embedding, b=embeddings)[0]\n",
    "    top_results_dot_product = torch.topk(dot_scores, k=k_resources_to_return)\n",
    "    texts = []\n",
    "    for idx in top_results_dot_product[1].to(\"cpu\"):\n",
    "        index = int(idx)\n",
    "        texts.append(df.iloc[index][\"sentence_chunk\"])\n",
    "    return texts\n",
    "\n",
    "\n",
    "def make_prompt(query,\n",
    "                rag_text=None,\n",
    "                ):\n",
    "    sys_prompt = \"You are a university professor. The user will ask you to explain a concept. Your task is to explain the concept as fully as you can, and maintain a clear and concise chain of thought. Afterwards, summarize what you have written and write a report.\"\n",
    "    if rag_text:\n",
    "        query = f\"You may use the following pieces of text for context:\\n {rag_text}\\n Now use the context items to answer the following prompt:\\n {query}\"\n",
    "    prompt = f\"{sys_prompt}\\n {query}\"\n",
    "    chat = [{ \"role\": \"user\", \"content\": prompt},]\n",
    "    prompt = tokenizer.apply_chat_template(chat, tokenize=False, add_generation_prompt=True)\n",
    "    return prompt\n",
    "\n",
    "\n",
    "def ask(query, \n",
    "        max_new_tokens = 512, \n",
    "        num_answers = 1,\n",
    "        top_k_rag = 4,\n",
    "        ):\n",
    "    topk = retrieve_topk_texts(query, k_resources_to_return=top_k_rag)\n",
    "    rag_text = \"\"\n",
    "    for chunk in topk:\n",
    "        rag_text += chunk + \"\\n\"\n",
    "    prompt = make_prompt(query, rag_text)\n",
    "    model_inputs = tokenizer([prompt]*num_answers, return_tensors=\"pt\").to(device)\n",
    "    generated_ids = model.generate(**model_inputs, max_new_tokens=max_new_tokens, do_sample=True)\n",
    "    out = tokenizer.batch_decode(generated_ids)\n",
    "    print(f\"RAG context:\\n {rag_text}\")\n",
    "    for output in out:\n",
    "        print(\"----------\")\n",
    "        print(output.replace(prompt,\"\"))\n",
    "\n",
    "\n",
    "def ask_noRAG(query,\n",
    "              max_new_tokens = 512, \n",
    "              num_answers = 1,\n",
    "              ):\n",
    "    prompt = make_prompt(query)\n",
    "    model_inputs = tokenizer([prompt]*num_answers, return_tensors=\"pt\").to(device)\n",
    "    generated_ids = model.generate(**model_inputs, max_new_tokens=max_new_tokens, do_sample=True)\n",
    "    out = tokenizer.batch_decode(generated_ids)\n",
    "    for output in out:\n",
    "        print(\"----------\")\n",
    "        print(output.replace(prompt,\"\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "<bos>Let's break down the concept of intrinsic value in a company.  \"Intrinsic value\" is essentially the real, underlying worth (potential) of a company, independent of market sentiment, investor psychology, or current stock price. Determining this value gives you a theoretical measure of \"true\" value that can help you compare different businesses and determine if current market prices are fair. \n",
      "\n",
      "Now, here are some of the key approaches to calculate intrinsic value, along with examples:\n",
      "\n",
      "**1. Discounted Cash Flow (DCF) Analysis:**\n",
      "\n",
      "* **Theory:** Businesses generate cash, and this cash represents value. DCF analyses future cash flows and discounts them back to today's dollars using a discount rate that reflects the risks inherent to the company.\n",
      "* **Steps:**\n",
      "    1. **Forecasting:** Project cash flows for 5-10 years (longer for more mature companies).  Consider revenue, expenses, capital expenditures, and working capital.\n",
      "    2. **Discount Rate:**  Calculate the appropriate discount rate. This is the desired rate of return an investor requires to compensate for the risk involved.  Use WACC (weighted average cost of capital) calculation method.\n",
      "    3. **Calculate the terminal value:** Project the cash flows beyond the initial forecast to estimate how much value will be generated in the future. This is often linked to residual value from operations or growth potential. \n",
      "    4. **Discount the present value:** Sum the present value of all future cash flows and add that sum to the terminal value of the company. \n",
      "\n",
      "* **Example:** A fast-growing start-up company selling digital marketing services.\n",
      "    * Projected earnings for the next 3 years: $1 million, $2 million, $3 million\n",
      "    * Discount rate: 12%\n",
      "    * Terminal value (using a terminal growth rate of 5%): $10 million\n",
      "    * Total discounted cash flow (DCF): $1 million + $2 million + $3 million * (1-.05)^3 + $10 million = **$16.60 million.** \n",
      "* **Limitations:**  DCF models are sensitive to assumptions about future cash flows, growth rates, and discount rates. They assume the company's potential is solely through projected cash flows, which might be risky for newer businesses. \n",
      "\n",
      "**2. Comparable Company Analysis (CCA):**\n",
      "\n",
      "* **Theory:** You compare a company's key financial metrics to a group of similar\n",
      "----------------- No RAG above ----------------- Yes RAG below -----------------\n"
     ]
    }
   ],
   "source": [
    "input_text = \"How should I determine the intrinsic value of a company? Can you provide some example computations for me to consider?\"\n",
    "\n",
    "# Generate text without RAG\n",
    "ask_noRAG(input_text, num_answers=1)\n",
    "\n",
    "print(\"----------------- No RAG above ----------------- Yes RAG below -----------------\")\n",
    "# Generate text with RAG\n",
    "ask(input_text, num_answers=1, top_k_rag=4)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
